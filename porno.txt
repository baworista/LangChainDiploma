graph.py
CONTENT:
==================
from langchain.agents import initialize_agent
from langchain_openai import ChatOpenAI
from langgraph.constants import START, END
from langgraph.graph import StateGraph
from langgraph.prebuilt import ToolNode
from auth_utils import auth_func
from graphSupervisor.nodes.analyst import *
from graphSupervisor import state
from graphSupervisor.nodes.supervisor import supervisor_decision, create_analysts_tool, supervisor_node
from graphSupervisor.state import OverallState, AnalystState

auth_func()

model = ChatOpenAI(temperature=0.0, model_name="gpt-4o-mini")


# Define simple test functions for nodes
def testAnalyst(state):
    print(f"Function call for {state.get('node_name', 'unknown node')}")
    return state  # Return the same state for simplicity


# Build the graph
app_builder = StateGraph(OverallState)

# Add the supervisor node
app_builder.add_node("supervisor", lambda state: supervisor_node(state, app_builder))

# Add the start and end points
app_builder.add_edge(START, "supervisor")

# Add the supervisor decision logic
app_builder.add_conditional_edges(
    "supervisor",
    supervisor_decision,
    [END]  # Default to end; dynamic nodes will be added during runtime
)

# Compile the graph
graphSupervisor = app_builder.compile()

# Save as PNG
graph_image = graphSupervisor.get_graph().draw_mermaid_png()
with open("graph_diagram.png", "wb") as file:
    file.write(graph_image)
print("Saved as PNG 'graph_diagram.png'")


# Thread configuration and graph input
thread = {"configurable": {"thread_id": "1"}}

user_input = {
    "topic": "Help a multinational manufacturing company in their journey to product management maturity.",
}

# response = graph.invoke(user_input, thread)
#
# print(response)

# Stream through the graph with the user-defined task
for state in graphSupervisor.stream(user_input, thread):
    print("-" * 50)  # Separator for readability
    print("Current State (Raw):", state)  # Print the entire state for debugging

    # Extract the current node's state dynamically
    current_node_state = next(iter(state.values()))  # Get the first value from the dictionary

    # Safely access keys from the current node's state
    print("Processed State:")
    print(f"Topic: {current_node_state.get('topic', 'N/A')}")
    print("-" * 50)  # Separator for clarity

==================

state.py
CONTENT:
==================
from typing import List, Dict, Any
from pydantic import BaseModel, Field
from typing_extensions import TypedDict

class Analyst(BaseModel):
    name: str = Field(
        description="The human-like name of the analyst persona. "
                    "Ensure the name is realistic and fits the persona."
    )
    role: str = Field(
        description="The specific role of the analyst in the context of the research topic. "
                    "Clearly defines the focus area such as 'Human Resources Analyst' or 'Business Process Analyst'."
    )
    description: str = Field(
        description="A detailed description of the analyst's focus, key competencies, tasks within the project, "
                    "concerns, and motives. This should align with the research topic and the analyst's role."
    )


    @property
    def persona(self) -> str:
        return f"Name: {self.name}\nRole: {self.role}\nDescription: {self.description}\n"


class Perspectives(BaseModel):
    analysts: List[Analyst] = Field(
        description="Comprehensive list of analysts with their roles and description.",
    )


# Individual state for each analyst
class AnalystState(TypedDict):
    analyst_name: str  # Name of the analyst (e.g., HRAnalyst, BPAnalyst)
    topic: str  # Topic assigned to the analyst
    goals: str  # Goals or focus of this analyst (e.g., HR-specific goals)
    diagnosis: List[str]  # Analyst-specific diagnosis
    recommendations: List[str]  # Analyst-specific recommendations


# Overall state for the supervisor
class OverallState(TypedDict):
    topic: str  # Overall topic of analysis
    questionnaire: str  # Questionnaire results or user input
    analysts: List[Analyst]  # All analysts
    analyst_progress: Dict[str, bool]  # Progress of each analyst (e.g., {'HRAnalyst': True})
    aggregated_diagnosis: List[str]  # Combined diagnosis from all analysts
    aggregated_recommendations: List[str]  # Combined recommendations from all analysts
    final_report: str  # Final report generated after all analysts complete their tasks
    analyst_states: Dict[str, AnalystState]  # Individual states for each analyst



==================

supervisor.py
CONTENT:
==================
import json
from typing import List

from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import StateGraph
from langgraph.prebuilt.chat_agent_executor import AgentState

from auth_utils import auth_func
from langchain_openai import ChatOpenAI
from langgraph.constants import START, END

from graphSupervisor.nodes.analyst import analyst_node
from graphSupervisor.state import OverallState, Perspectives, AnalystState
from langchain.tools import tool
from langgraph.constants import Send

# Authenticate and initialize LLM
auth_func()
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)  # should be gpt-4o

# Analyst creation instructions
analyst_instructions = """
You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:

First, review the provided research topic.

Next, create four AI analysts:
1. Human Resources Analyst, focusing on team dynamics and performance, team collaboration, and human trainings and development in the context of the topic.
2. Business Process Analyst, focusing on business process optimization, business process automation, and business process management in the context of the topic.
3. Knowledge Management Analyst, focusing on knowledge management processes, knowledge sharing, and knowledge tools in the context of the topic.
4. IT Systems Analyst, specializing in IT systems, IT tools, and IT strategies in the context of the topic.
"""


@tool
def create_analysts_tool(topic: str) -> dict:
    """
    Tool to create AI analysts based on a provided topic.
    Accepts the topic as a string and returns the generated analysts in a JSON-serializable format.
    """
    structured_llm = llm.with_structured_output(Perspectives)

    # Формируем запрос для LLM
    system_message = SystemMessage(content=analyst_instructions)
    human_message = HumanMessage(content=f"Generate the set of analysts. Here is the topic: {topic}.")

    # Генерация аналитиков
    perspectives: Perspectives = structured_llm.invoke([system_message, human_message])

    # Преобразуем в сериализуемый формат
    serialized_analysts = [
        {
            "name": analyst.name,
            "role": analyst.role,
            "description": analyst.description,
        }
        for analyst in perspectives.analysts
    ]

    return {"analysts": serialized_analysts}

@tool
def write_report(state: OverallState):
    """
    Объединяет результаты всех аналитиков и формирует финальный отчет.

    Args:
        state (OverallState): Состояние, содержащее результаты всех аналитиков.

    Returns:
        dict: Обновленное состояние с финальным отчетом.
    """
    print("... Write Report ...")

    aggregated_diagnosis = []
    aggregated_recommendations = []

    # Сбор данных из консультирования
    for analyst in state["analysts"]:
        diagnosis = analyst.get("diagnosis", [])
        recommendations = analyst.get("recommendations", [])
        aggregated_diagnosis.extend(diagnosis)
        aggregated_recommendations.extend(recommendations)

    # Инструкции для генерации отчёта
    writing_instructions = """
    You are an expert tasked with summarizing the findings of a consulting process.
    Use the following structure to create the report:

    1. Introduction: Provide a brief summary of the consulting process.
    2. Diagnoses: Summarize the key diagnoses in a concise and clear manner.
    3. Recommendations: Provide actionable recommendations for the client.
    4. Conclusion: Conclude the report with a forward-looking statement.

    Diagnoses:
    {diagnosis}

    Recommendations:
    {recommendations}
    """

    # Формирование сообщения для LLM
    system_message = writing_instructions.format(
        diagnosis="\n".join(aggregated_diagnosis),
        recommendations="\n".join(aggregated_recommendations),
    )

    # Генерация отчёта с помощью LLM
    report_response = llm.invoke([SystemMessage(content=system_message)])
    final_report = report_response.content.strip()

    # Формирование итогового состояния
    state["aggregated_diagnosis"] = aggregated_diagnosis
    state["aggregated_recommendations"] = aggregated_recommendations
    state["final_report"] = final_report

    print("Final report generated.")
    return state


def supervisor_decision(state: OverallState):
    """
    Invokes the supervisor decision function.
    """
    current_step = state.get("current_step", 0)
    max_steps = 4  # Number of analysts
    state["current_step"] = current_step + 1

    if current_step < max_steps:
        return ["HRAnalyst", "BPAnalyst", "KMAnalyst", "ITAnalyst"][current_step]
    return END

@tool
def initiate_consulting_threads(topic: str, analysts: List[dict]) -> dict:
    """
    Initiate parallel agent workflow using isolated substates for each analyst.

    Args:
        topic (str): The overall topic of analysis.
        analysts (List[dict]): List of analyst definitions containing name, role, and description.
        questionnaire (str): The questionnaire results or user input.

    Returns:
        Dict[str, AnalystState]: Dictionary of individual analyst states indexed by their names.
    """
    print("... Initiate analysis ...")
    print(f"Analysts: {analysts}")
    print(f"Topic: {topic}")
    print("... Analysis initiated...")

    # Create individual states for each analyst
    analyst_states = {}
    for analyst in analysts:
        analyst_state = AnalystState(
            analyst_name=analyst["name"],
            topic=topic,
            goals=f"Name: {analyst['name']}\nRole: {analyst['role']}\nDescription: {analyst['description']}",
            diagnosis=[],
            recommendations=[],
        )
        analyst_states[analyst["name"]] = analyst_state

    return analyst_states



def supervisor_node(state: OverallState, app_builder: StateGraph):
    """
    Invokes the supervisor node and dynamically adds analyst nodes to the graph.
    """

    # Check if there are agents
    if "analysts" not in state or not state["analysts"]:
        # Generate analysts
        generated_analysts = create_analysts_tool.invoke(state["topic"])
        state.update(generated_analysts)
        state["analyst_progress"] = {analyst["name"]: False for analyst in state["analysts"]}

        # Generate individual analyst states
        input_payload = {"topic": state["topic"], "analysts": state["analysts"]}
        analyst_states = initiate_consulting_threads.invoke(input_payload)

        # Add dynamic nodes to the graph
        for analyst_name, analyst_state in analyst_states.items():
            node_name = f"{analyst_name.replace(' ', '')}Node"  # Ensure unique node names
            app_builder.add_node(node_name, lambda s: analyst_node(analyst_state))
            app_builder.add_edge(node_name, "supervisor")  # Add edge back to the supervisor

        print("Analyst nodes added dynamically.")

        # # Save updated graph as PNG for visualization
        # graph_image = app_builder.get_graph().draw_mermaid_png()
        # with open("graph_diagram_updated.png", "wb") as file:
        #     file.write(graph_image)
        # print("Saved updated graph as PNG 'graph_diagram_updated.png'.")

    # Invoke tools to process the state
    tools = [initiate_consulting_threads, write_report]
    tool_mapping = {tool.name.lower(): tool for tool in tools}
    print(tool_mapping)

    llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)

    # Call tools
    response = llm_with_tools.invoke(state["topic"])
    print("Response from llm with tools:", response.tool_calls)

    for tool_call in response.tool_calls:
        tool_name = tool_call["name"].lower()
        tool_args = tool_call["args"]

        # Check if the tool exists in the mapping
        if tool_name not in tool_mapping:
            raise ValueError(f"Tool '{tool_name}' not found in the defined tools.")

        selected_tool = tool_mapping[tool_name]
        tool_response = selected_tool.invoke(tool_args)
        print(f"Output from tool '{tool_name}':", tool_response)

        # Update only specific fields in the state
        state.update(tool_response)

    return state




# # Example usage
# if __name__ == "__main__":
#     # Mock OverallState for demonstration
#     state = OverallState(topic="Digital Transformation in Organizations")
#
#     print("initial_state: ", json.dumps(state, indent=4, ensure_ascii=False))
#
#     # Invoke the model with the tools and initial state
#     supervisor_node(state)
#
#     # Print the updated state
#     print("update_state:", json.dumps(state, indent=4, ensure_ascii=False))





==================

analyst.py
CONTENT:
==================
from langchain_core.messages import SystemMessage
from langchain_openai import ChatOpenAI

from graphSupervisor.state import AnalystState
from graphSupervisor.state import OverallState

from auth_utils import auth_func

auth_func()

llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)

def diagnose_tool(state:AnalystState):

    diagnosis_instructions = """You are an analyst tasked with needs analysis of Your customer.
    Here is Your detailed persona, including role in the projects, competencies and tasks: {goals}

    Your goal is diagnose the current state of the customer basing on questionnaire results.
    Here is the questionnaire results: {questionnaire}

    Generate only a diagnosis based on the questionnaire results. 
    Your diagnosis should solely focus on Your persona, competencies and tasks.
    Do not diagnose aspects outside of Your persona competencies.
    Do not recommend any solutions yet. 
    """

    analyst = state["analyst"]
    topic = state["topic"]
    print(f"Analyst: {analyst.name}")
    # print(f"Topic: {topic}")
    questionnaire = state.get("questionnaire", "Questionnaire results")  # Get questionnaire or use default

    # Generate diagnosis
    system_message = diagnosis_instructions.format(
        goals=analyst.persona,
        questionnaire=questionnaire
    )
    diagnosis_result = llm.invoke([SystemMessage(content=system_message)])
    print("... Diagnose end...")
    return {
        "diagnosis": [diagnosis_result.content]  # Store current diagnosis
    }

def recommend_tool(state: AnalystState)-> OverallState:
    recommendations_instructions = """You are an analyst tasked with helping Your customer in the {topic}.".
    Here is Your detailed persona, including role in the projects, competencies and tasks: {goals}

    Your goal is make constructive and interesting recommendations basing on an initial diagnosis.
    1. Constructive: Recommendations that are helpful and actionable.
    2. Specific: Recommendations that avoid generalities and include specific examples from the expert.
    3. Managable: Recommendations that are realistic and can be implemented by the customer.

    Here is the diagnosis: {diagnosis}

    Generate only recommendation grounded in the diagnosis.
    Your recommendation should solely be inline with Your persona, competencies, and tasks.
    Do not make recommendations in aspects outside of Your persona, competencies, and tasks.
    """

    """ Node to make recommendations based on the diagnosis """
    print("... Recommend start ...")
    # Get state
    analyst = state["analyst"]
    print(f"Analyst: {analyst.name}")
    topic = state['topic']
    # print(f"Topic: {topic}")
    diagnosis = state['diagnosis']

    # Generate question
    system_message = recommendations_instructions.format(topic=topic, goals=analyst.persona, diagnosis=diagnosis)
    recommendation = llm.invoke([SystemMessage(content=system_message)])
    # Write messages to state
    return {"recommendations": [recommendation.content]}


def analyst_node(state: AnalystState) -> AnalystState:
    """
    Processes an individual analyst's state and updates it with diagnosis and recommendations.

    Args:
        state (AnalystState): The specific state for the analyst.

    Returns:
        AnalystState: Updated state with diagnosis and recommendations.
    """
    print(f"Processing {state['analyst_name']}...")

    # Generate diagnosis
    diagnosis_result = diagnose_tool(state)
    state.update(diagnosis_result)

    # Generate recommendations
    recommendation_result = recommend_tool(state)
    state.update(recommendation_result)

    print(f"Completed analysis for {state['analyst_name']}")
    return state






# def analyst_node(topic: str, name: str, role: str, description: str) -> AnalystState:
#     """
#     Processes an individual analyst and generates their unique AnalystState.
#
#     Args:
#         topic (str): The topic of the analysis.
#         name (str): The name of the analyst.
#         role (str): The role of the analyst.
#         description (str): The description of the analyst's focus and tasks.
#
#     Returns:
#         AnalystState: The unique state for the processed analyst.
#     """
#     print(f"Processing {name}...")
#     print(f"Name: {name}")
#     print(f"Topic: {topic}")
#     print(f"Role: {role}")
#     print(f"Description: {description}")
#
#     # Create and return the unique AnalystState
#     analyst_state = {
#         "analyst_name": name,
#         "topic": topic,
#         "role": role,
#         "description": description,
#     }
#
#     print(f"Generated state for {name}:\n{analyst_state}")
#     return analyst_state



==================

