graph.py
CONTENT:
==================
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langgraph.constants import START, END
from langgraph.graph import StateGraph

from nodes.supervisor_node import supervisor_node
from nodes.team_node import *
from states import *

load_dotenv()
model = ChatOpenAI(temperature=0.1, model_name="gpt-4o-mini")

# Build the graph
app_builder = StateGraph(OverallState)

# Add nodes
app_builder.add_node("Supervisor", supervisor_node)

app_builder.add_node("HR_Analyst", analyst_node)
app_builder.add_node("BP_Analyst", analyst_node)
app_builder.add_node("KM_Analyst", analyst_node)
app_builder.add_node("IT_Analyst", analyst_node)

app_builder.add_node("HR_Reviewer", reviewer_node)
app_builder.add_node("BP_Reviewer", reviewer_node)
app_builder.add_node("KM_Reviewer", reviewer_node)
app_builder.add_node("IT_Reviewer", reviewer_node)

app_builder.add_node("Report_Writer", reviewer_node)
# app_builder.add_node("supervisor_tools", ToolNode([create_analysts_tool])) - additional for graph visualizing

# Set start and end points
app_builder.add_edge(START, 'Supervisor')

app_builder.add_edge('Supervisor', 'HR_Analyst')
app_builder.add_edge('Supervisor', 'BP_Analyst')
app_builder.add_edge('Supervisor', 'KM_Analyst')
app_builder.add_edge('Supervisor', 'IT_Analyst')

app_builder.add_edge('HR_Analyst', 'HR_Reviewer')
app_builder.add_edge('BP_Analyst', 'BP_Reviewer')
app_builder.add_edge('KM_Analyst', 'KM_Reviewer')
app_builder.add_edge('IT_Analyst', 'IT_Reviewer')

app_builder.add_conditional_edges('HR_Reviewer', if_continue_conversation, ['HR_Analyst', 'Supervisor'])
app_builder.add_conditional_edges('BP_Reviewer', if_continue_conversation, ['BP_Analyst', 'Supervisor'])
app_builder.add_conditional_edges('KM_Reviewer', if_continue_conversation, ['KM_Analyst', 'Supervisor'])
app_builder.add_conditional_edges('IT_Reviewer', if_continue_conversation, ['IT_Analyst', 'Supervisor'])

app_builder.add_edge('Supervisor', 'Report_Writer')

app_builder.add_edge('Report_Writer', END)

# Compile the graph
graphSupervisor = app_builder.compile()

# Save as PNG
graph_image = graphSupervisor.get_graph().draw_mermaid_png()
with open("supervisor_graph_diagram.png", "wb") as file:
    file.write(graph_image)
print("Saved as PNG 'supervisor_graph_diagram.png'")

# Thread configuration and graph input
thread = {"configurable": {"thread_id": "1"}}

user_input = {
    "topic": "Help a multinational manufacturing company in their journey to product management maturity.",
}

# response = graphSupervisor.invoke(user_input, thread)
#
# print(response)

# # Stream through the graph with the user-defined task
# for state in graphSupervisor.stream(user_input, thread):
#     print("-" * 50)  # Separator for readability
#     print("Current State (Raw):", state)  # Print the entire state for debugging
#
#     # Extract the current node's state dynamically
#     current_node_state = next(iter(state.values()))  # Get the first value from the dictionary
#
#     # Safely access keys from the current node's state
#     print("Processed State:")
#     print(f"Topic: {current_node_state.get('topic', 'N/A')}")
#     print("-" * 50)  # Separator for clarity

==================

states.py
CONTENT:
==================
import operator
from typing import List, Dict, Annotated, Sequence

from langchain_core.messages import BaseMessage
from pydantic import BaseModel, Field
from typing_extensions import TypedDict


class ResearchTeam(BaseModel):
    name: str = Field(
        description="The name of the research team that reflects the combined expertise of the analyst and reviewer. "
                    "It should clearly convey the team's overarching responsibility and domain focus. "
                    "Ensure the name is concise, professional, and indicative of the team's key role, "
                    "e.g., 'Human Resources Insights Team' or 'Process Optimization Experts'."
    )

    description: str = Field(
        description="Short description of what this team is response for."
    )

    analyst_prompt: str = Field(
        description="The specific prompt for the analyst in the context of the research topic. "
                    "Clearly defines the focus area such as 'Human Resources' or 'Business Process'. "
                    "\n +"
                    "A description of the analyst's focus, key competencies, tasks within the project, "
                    "concerns, and motives. This should align with the research topic and the analyst's role."
    )

    reviewer_prompt: str = Field(
        description="The specific prompt for the reviewer in the context of the research topic. "
                    "Clearly defines the focus area such as 'Human Resources' or 'Business Process'. "
                    "\n +"
                    "A description of the reviewer's focus, key competencies, tasks within the project, "
                    "concerns, and motives. This should align with the research topic and the reviewer's role."
    )

    @property
    def experts(self) -> str:
        """
        Provides a detailed representation of the research team's persona,
        including its name, description, and the specific prompts for the analyst and reviewer.
        """
        return (
            f"Team Name: {self.name}\n"
            f"Description: {self.description}\n\n"
            f"Analyst Prompt:\n{self.analyst_prompt}\n\n"
            f"Reviewer Prompt:\n{self.reviewer_prompt}\n"
        )


class Perspectives(BaseModel):
    teams: List[ResearchTeam] = Field(
        description="List of research teams where each team contains name, description and analyst - reviewer duo prompts",
    )


# Individual state for each analyst
class ResearchState(TypedDict):
    research_id: int
    research_name: str
    topic: str  # Topic assigned to the analyst
    questionnaire: str  # Questionnaire results or user input
    messages: Annotated[Sequence[BaseMessage], operator.add]  # Their conversation
    result: str
    analyst_prompt: str  # Their info
    reviewer_prompt: str


# Overall state for the supervisor
class OverallState(TypedDict):
    topic: str  # Overall topic of analysis
    questionnaire: str  # Questionnaire results or user input
    reviewer_final_overview: Dict[int, str]  # Four reviewers answers
    final_report: str  # Final report generated after all analysts complete their tasks
    teams: List[ResearchTeam]
    teams_states: List[ResearchState]

==================

supervisor_node.py
CONTENT:
==================
import json
from typing import List

from dotenv import load_dotenv
from langchain.tools import tool
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI

from supervisor_simple.states import OverallState, ResearchState, Perspectives

# LLM Initialization
load_dotenv()
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

team_creation_instructions = """
You are tasked with creating AI research teams, each consisting of an analyst and a reviewer. Follow these instructions:

1. Review the provided research topic.
2. Generate four research teams:
    a. Human Resources Team: Focused on HR issues like team dynamics, performance, and training.
    b. Business Process Team: Specializing in process optimization and automation.
    c. Knowledge Management Team: Concentrating on knowledge sharing and tools.
    d. IT Systems Team: Addressing IT strategies and tools.
3. Each team must have a detailed name, description and prompts reflecting their responsibilities.
"""


@tool
def create_research_teams_tool(topic: str) -> dict:
    """
    Generates a list of research teams based on the given topic.
    """
    structured_llm = llm.with_structured_output(Perspectives)

    # Формируем запрос для LLM
    system_message = SystemMessage(content=team_creation_instructions)
    human_message = HumanMessage(content=f"Generate the teams for the topic: {topic}.")

    # Генерация аналитиков
    perspectives: Perspectives = structured_llm.invoke([system_message, human_message])

    # Преобразуем в сериализуемый формат
    serialized_teams = [
        {
            "name": team.name,
            "description": team.description,
            "analyst_prompt": team.analyst_prompt,
            "reviewer_prompt": team.reviewer_prompt,
        }
        for team in perspectives.teams
    ]

    return {"teams": serialized_teams}


@tool
def initialize_research_states(topic: str, teams: List[dict]) -> List[ResearchState]:
    """
    Initializes states for each research team.
    """
    teams_states = []
    for idx, team in enumerate(teams):
        research_state = ResearchState(
            research_id=idx + 1,
            research_name=team["name"],
            topic=topic,
            questionnaire="",
            messages=[],  # Empty conversation history initially
            result="",
            analyst_prompt=f"Analyst: {team['description']}",
            reviewer_prompt=f"Reviewer: {team['description']}",
        )
        teams_states.append(research_state)

    return {"teams_states": teams_states}


def supervisor_node(state: OverallState):
    """
    Supervisor node for orchestrating the research workflow.
    """
    if "teams_states" not in state or not state["teams_states"]:
        # Generate teams and initialize states
        generated_teams = create_research_teams_tool.invoke({"topic": state["topic"]})
        state["teams"] = generated_teams["teams"]

        initialized_states = initialize_research_states.invoke(
            {"topic": state["topic"], "teams": state["teams"]})
        state["teams_states"] = initialized_states["teams_states"]

    return state


# Example usage
if __name__ == "__main__":
    # Mock OverallState for demonstration
    state = OverallState(topic="Digital Transformation in Organizations")

    print("initial_state: ", json.dumps(state, indent=4, ensure_ascii=False))

    # Invoke the model with the tools and initial state
    supervisor_node(state)

    # Print the updated state
    print("update_state:", json.dumps(state, indent=4, ensure_ascii=False))

==================

team_node.py
CONTENT:
==================
def analyst_node():
    pass


def reviewer_node():
    pass


def if_continue_conversation():
    pass

==================

