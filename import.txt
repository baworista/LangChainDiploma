graph.py
CONTENT:
==================
from langgraph.constants import START
from langgraph.graph import StateGraph

from graphSupervisor.nodes.report_writer_node import *
from graphSupervisor.nodes.supervisor_node import *
from graphSupervisor.nodes.team_node import *
from graphSupervisor.states import *


load_dotenv()
model = ChatOpenAI(temperature=0.1, model_name="gpt-4o-mini")

# Define subgraphs
def create_team_builder():
    team_builder = StateGraph(ResearchState)
    team_builder.add_node("Analyst", analyst_node)
    team_builder.add_node("Reviewer", reviewer_node)

    team_builder.add_edge(START, "Analyst")

    team_builder.add_conditional_edges("Analyst", should_continue, ["Reviewer", END])
    team_builder.add_edge("Reviewer", "Analyst")
    return team_builder


hr_team_builder = create_team_builder()
bp_team_builder = create_team_builder()
km_team_builder = create_team_builder()
it_team_builder = create_team_builder()

app_builder = StateGraph(OverallState)

app_builder.add_node("Supervisor", supervisor_node)
app_builder.add_node("Report_Writer", report_writer_node)

app_builder.add_node("HR_Team", hr_team_builder.compile())
app_builder.add_node("BP_Team", bp_team_builder.compile())
app_builder.add_node("KM_Team", km_team_builder.compile())
app_builder.add_node("IT_Team", it_team_builder.compile())


# Build the main graph
app_builder.add_edge(START, 'Supervisor')

# app_builder.add_edge('Supervisor', 'HR_Team')
# app_builder.add_edge('Supervisor', 'BP_Team')
# app_builder.add_edge('Supervisor', 'KM_Team')
# app_builder.add_edge('Supervisor', 'IT_Team')

app_builder.add_conditional_edges('Supervisor', define_edge,
                                  ["HR_Team", "BP_Team", "IT_Team", "KM_Team", "Report_Writer", END]) # Could also be added Supervisot if we will make llm in that node



app_builder.add_edge('HR_Team', 'Supervisor')
app_builder.add_edge('BP_Team', 'Supervisor')
app_builder.add_edge('KM_Team', 'Supervisor')
app_builder.add_edge('IT_Team', 'Supervisor')
app_builder.add_edge('Report_Writer', 'Supervisor')

# app_builder.add_edge('Supervisor', 'Report_Writer')  # wait for others(COMMAND)
# app_builder.add_conditional_edges(
#     "Supervisor",
#     lambda state:
#     "Report_Writer" if len(state["reviewer_final_overview"]) == 4
#     else "Supervisor"
# )

app = app_builder.compile()

# Compile the graph
graphSupervisor = app_builder.compile()

# Save as PNG
graph_image = graphSupervisor.get_graph(xray=1).draw_mermaid_png()
with open("supervisor_graph_diagram.png", "wb") as file:
    file.write(graph_image)
print("Saved as PNG 'supervisor_graph_diagram.png'")




# Thread configuration and graph input
thread = {"configurable": {"thread_id": "1"}}

# Load from file
with open("../data/answer_1.json", "r") as file:
    data = json.load(file)

user_input = {
    "topic": "Help a multinational manufacturing company in their journey to product management maturity.",
    "questionnaire" :  data
}

response = graphSupervisor.invoke(user_input, thread)

final_report = response.get("final_report")

if final_report:
    print(final_report.content)
else:
    print("Final report is missing.")

==================

states.py
CONTENT:
==================
import operator
from typing import List, Annotated

from langgraph.graph import MessagesState
from pydantic import BaseModel, Field
from typing_extensions import TypedDict
from schema import *


# Individual state for each analyst and reviewer team
class ResearchState(MessagesState):
    name: str
    team_topic: str
    description: str  # Description of team's responsibility and capabilities
    team_questionnaire: str # Questionnaire results or user input
    reviews: Annotated[List[str], operator.add]  # Four reviewers answers
    analyst: Person  # Their info
    reviewer: Person


def deduplicate_merge(old_reviews: List[str], new_reviews: List[str]) -> List[str]:
    return list(set(old_reviews).union(new_reviews))

# Overall state for the supervisor
class OverallState(TypedDict):
    topic: str  # Overall topic of analysis
    questionnaire: str  # Questionnaire results or user input
    reviews: Annotated[List[str], deduplicate_merge]  # Four reviewers answers
    final_report: str  # Final report generated after all analysts complete their tasks
    teams: List[ResearchTeam]

==================

schema.py
CONTENT:
==================
from typing import List

from pydantic import BaseModel, Field

class Person(BaseModel):
    name: str = Field(
        description="Human-like person's name from anime"
    )
    role: str = Field(
        description="Role of the person in the team and in context of the topic.",
    )
    description: str = Field(
        description="Description of the person's focus, key competencies, tasks in the project and concerns, and motives.",
    )

    @property
    def persona(self) -> str:
        return f"Name: {self.name}\nRole: {self.role}\nDescription: {self.description}\n"


class ResearchTeam(BaseModel):
    name: str = Field(
        description="Use only provided in system message names"
    )

    description: str = Field(
        description="Short description of what this team is response for."
    )

    analyst: Person = Field(
        description="Analyst person"
    )

    reviewer: Person = Field(
        description="Reviewer person"
    )

    @property
    def team(self) -> str:
        """
        Provides a detailed representation of the research team's persona,
        including its name, description, and the specific prompts for the analyst and reviewer.
        """
        return (
            f"Team Name: {self.name}\n"
            f"Description: {self.description}\n\n"
            f"Analyst :\n{self.analyst}\n\n"
            f"Reviewer :\n{self.reviewer}\n"
        )


class Perspectives(BaseModel):
    teams: List[ResearchTeam] = Field(
        description="List of research teams where each team contains name, description and analyst - reviewer duo prompts",
    )
==================

supervisor_node.py
CONTENT:
==================
import json
import os
from typing import List
from dotenv import load_dotenv
from langchain.tools import tool
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.constants import Send
from langgraph.constants import END

from graphSupervisor.states import OverallState, Perspectives

# LLM Initialization
load_dotenv()
llm = ChatOpenAI(model=os.getenv("MODEL_SUPERVISOR"), temperature=0)

team_creation_instructions = """
You are tasked with creating AI research teams, each consisting of an analyst and a reviewer. Follow these instructions:
Use provided in prompts names
1. Review the provided research topic.
2. Generate four research teams strictly using provided names:
    a. **HR_Team**: Focused on HR issues like team dynamics, performance, and training.
    b. **BP_Team**: Specializing in process optimization and automation.
    c. **KM_Team**: Concentrating on knowledge sharing and tools.
    d. **IT_Team**: Addressing IT strategies and tools.
3. Each team must have explicitly provided name, description and prompts reflecting their responsibilities.
4. For agents
"""


def define_edge(state: OverallState):
    """
    Initializes states for each research team.
    """
    # print("This is log info FROM DEFINE_EDGE about reviews list length: " + str(len(state["reviews"])))

    if "final_report" in state:
        return END

    if len(state["reviews"]) >= 4:
        return "Report_Writer"

    topic = state["topic"]
    teams = state["teams"]
    questionnaire = state["questionnaire"]

    print(f"Initializing research teams for topic: \n\t{topic}")

    return [
        Send(
            team["name"],
            {
                "name": team["name"],
                "team_topic": topic,  # Topic assigned to the analyst
                "description": team["description"],
                "team_questionnaire": questionnaire,
                "messages": [],
                "reviews": [],
                "analyst": team["analyst"],
                "reviewer": team["reviewer"],
            }
        ) for team in teams
    ]


@tool
def create_research_teams_tool(topic: str) -> dict:
    """
    Generates a list of research teams based on the given topic.
    """

    print(f"Creating research teams on topic: \n\t{topic}")
    structured_llm = llm.with_structured_output(Perspectives)

    # LLM Query
    system_message = SystemMessage(content=team_creation_instructions)
    human_message = HumanMessage(content=f"Generate the teams for the topic: {topic}.")

    # Teams generation
    perspectives: Perspectives = structured_llm.invoke([system_message, human_message])

    # Serialize
    serialized_teams = [
        {
            "name": team.name,
            "description": team.description,
            "analyst": team.analyst,
            "reviewer": team.reviewer,
        }
        for team in perspectives.teams
    ]

    return {"teams": serialized_teams}


def supervisor_node(state: OverallState):
    """
    Supervisor node for orchestrating the research workflow.
    """
    # print("This is log info FROM SUPERVISOR about reviews list length: " + str(len(state["reviews"])))

    if "reviews" not in state:
        state["reviews"] = []

    if "teams" not in state or not state["teams"]:
        # Generate teams and initialize states
        generated_teams = create_research_teams_tool.invoke({"topic": state["topic"]})
        state["teams"] = generated_teams["teams"]

    return state


# Example usage
# if __name__ == "__main__":
#     # Mock OverallState for demonstration
#     state = OverallState(topic="Digital Transformation in Organizations")
#
#     print("initial_state: ", json.dumps(state, indent=4, ensure_ascii=False))
#
#     # Invoke the model with the tools and initial state
#     supervisor_node(state)
#
#     # Print the updated state
#     print("update_state:", json.dumps(state, indent=4, ensure_ascii=False))

==================

team_node.py
CONTENT:
==================
import os
from pyexpat.errors import messages

from httpx import Headers
from langchain_core.messages import SystemMessage, AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langgraph.constants import END

from graphSupervisor.states import ResearchState

llm = ChatOpenAI(model_name=os.getenv("MODEL"), max_tokens=500)

analyst_prompt = """
# Role & Context
You are: {person}
You are in {team} with {reviewer}, who will provide a review and share their opinion with you.
You are tasked with performing a **needs analysis** for your customer on the topic: {topic}

# Data Source
Here are the **questionnaire results**: {questionnaire}

# Objective
Your primary goal is to **analyze the current state of the customer** based on the questionnaire results and, once received, **integrate the reviewer's feedback** into your analysis.

# Guidelines
- Generate **only an analysis** based on the questionnaire results.
- Focus **solely on your persona, competencies, and tasks**.

# Constraints
- **Do not analyze aspects outside of your persona or competencies.**
- **Do not recommend any solutions yet.**

# Final Note
Keep your analysis focused, clear, and aligned with the given responsibilities and data.
"""


reviewer_prompt = """
# Role & Context
You are: {person}
You are in {team} with {analyst}, who will make an analysis and share it with you.
You are tasked with assisting your analyst on the topic: {topic}

# Data Source
Here are the questionnaire results: {questionnaire}

# Objective
Your primary task is to create a constructive and insightful review based on the provided analysis and questionnaire results.

# Guidelines
1. **Constructive:** Provide actionable and helpful recommendations.
2. **Specific:** Avoid generalities; include clear examples directly tied to the analysis.
3. **Manageable:** Ensure your recommendations are practical and achievable for the customer.

# Constraints
- Base your recommendations **solely on the provided analysis**.
- Stay **aligned with your role, expertise, and responsibilities**.
- Avoid commenting on aspects outside your defined scope.

# Final Note
Focus on delivering a review that adds value, clarity, and direction to the analysis provided.
"""



def analyst_node(state):
    topic = state["team_topic"]

    team_name = state["name"]
    team_description = state["description"]

    reviewer_info = state["reviewer"]
    analyst_info = state["analyst"]

    questionnaire = state["team_questionnaire"]

    print(f"Analyst node {team_name} activated.")

    system_prompt = analyst_prompt.format(topic=topic,
                                          team = team_name + "\n" + team_description,
                                          reviewer = reviewer_info,
                                          person = analyst_info,
                                          questionnaire = questionnaire)

    messages = state["messages"]

    if len(messages) != 0:
        last_message = "Your previous report: \n" + messages[-2].content +"\n\n\nReviewers recommendations: \n" + messages[-1].content
    else:
        last_message = ""

    print("++++++++++++++++++++++++++++++++++++++++")
    print(last_message)
    print("++++++++++++++++++++++++++++++++++++++++")

    llm_messages = [SystemMessage(content=system_prompt),
                last_message
                ]

    return {"messages": [llm.invoke(llm_messages).content]}
    # return {"messages": [AIMessage("Analyst answer " + state["analyst_prompt"][0:25])]  + state.get("messages", [])} # For test


def reviewer_node(state):
    topic = state["team_topic"]

    team_name = state["name"]
    team_description = state["description"]

    reviewer_info = state["reviewer"]
    analyst_info = state["analyst"]

    questionnaire = state["team_questionnaire"]

    print(f"Reviewer node {team_name} activated.")

    system_prompt = reviewer_prompt.format(topic=topic,
                                          team = team_name + "\n" + team_description,
                                          analyst = analyst_info,
                                          person = reviewer_info,
                                          questionnaire = questionnaire)



    last_message = state["messages"][-1]
    print("++++++++++++++++++++++++++++++++++++++++")
    print(last_message)
    print("++++++++++++++++++++++++++++++++++++++++")

    messages = [SystemMessage(content=system_prompt),
                last_message,
                ]


    return {"messages": [llm.invoke(messages).content]}
    # return {"messages": [AIMessage("Reviewers answer " + state["reviewer_prompt"][0:25])] + state.get("messages", [])} # For test


def should_continue(state: ResearchState):
    messages = state.get("messages", [])
    # Check if the number of messages is 6 or more
    if len(messages) >= 7:

        # Return the END constant and the overall state update
        state["reviews"].append(messages[-1].content)
        return END

    # If the condition is not met, return the next node
    return "Reviewer"


==================

report_writer_node.py
CONTENT:
==================
from dotenv import load_dotenv

from graphSupervisor.states import OverallState
from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
import os

load_dotenv()

llm = ChatOpenAI(model_name=os.getenv("MODEL"))

writing_instructions = """You are a senior consultant experienced in writing executive reports. Your goal is to write a comprehensive report based on the reviews provided by the analyst-reviewer teams.

The report should be structured, concise, and actionable. It should include an executive summary, an introduction, a detailed analysis, and a set of recommendations.

Here are the topic of task: {topic}

Here are the questionnaire: {questionnaire}

Here are reviews from teams: {reviews}.

Write a report from provided.
"""

def report_writer_node(state: OverallState):
    """ Node to summarize diagnosis and recommendations in a single report"""

    print("... Write Report ...")
    # Get state
    topic = state["topic"]
    questionnaire = state["questionnaire"]
    reviews = state["reviews"]

    # Generate question
    system_message = writing_instructions.format(topic=topic, questionnaire=questionnaire, reviews=reviews)
    report = llm.invoke([SystemMessage(content=system_message)])

    # Write messages to state
    return {"final_report": report}

==================

