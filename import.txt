graph.py
CONTENT:
==================
from langgraph.constants import START
from langgraph.graph import StateGraph

from graphSupervisor.nodes.report_writer_node import *
from graphSupervisor.nodes.supervisor_node import *
from graphSupervisor.nodes.team_node import *
from graphSupervisor.states import *


load_dotenv()
model = ChatOpenAI(temperature=0.1, model_name="gpt-4o-mini")

# Define subgraphs
def create_team_builder():
    team_builder = StateGraph(ResearchState)
    team_builder.add_node("Analyst", analyst_node)
    team_builder.add_node("Reviewer", reviewer_node)

    team_builder.set_entry_point("Analyst")
    
    team_builder.add_edge("Analyst", "Reviewer")
    team_builder.add_conditional_edges("Reviewer", should_continue, ["Analyst", END])
    return team_builder

hr_team_builder = create_team_builder()
bp_team_builder = create_team_builder()
km_team_builder = create_team_builder()
it_team_builder = create_team_builder()

app_builder = StateGraph(OverallState)

app_builder.add_node("Supervisor", supervisor_node)
app_builder.add_node("Report_Writer", report_writer)

app_builder.add_node("HR_Team", hr_team_builder.compile())
app_builder.add_node("BP_Team", bp_team_builder.compile())
app_builder.add_node("KM_Team", km_team_builder.compile())
app_builder.add_node("IT_Team", it_team_builder.compile())


# Build the main graph
app_builder.add_edge(START, 'Supervisor')

# app_builder.add_edge('Supervisor', 'HR_Team')
# app_builder.add_edge('Supervisor', 'BP_Team')
# app_builder.add_edge('Supervisor', 'KM_Team')
# app_builder.add_edge('Supervisor', 'IT_Team')

app_builder.add_conditional_edges('Supervisor', define_edge,
                                  ["HR_Team", "BP_Team", "IT_Team", "KM_Team", "Report_Writer", END]) # Could also be added Supervisot if we will make llm in that node



app_builder.add_edge('HR_Team', 'Supervisor')
app_builder.add_edge('BP_Team', 'Supervisor')
app_builder.add_edge('KM_Team', 'Supervisor')
app_builder.add_edge('IT_Team', 'Supervisor')
app_builder.add_edge('Report_Writer', 'Supervisor')

# app_builder.add_edge('Supervisor', 'Report_Writer')  # wait for others(COMMAND)
# app_builder.add_conditional_edges(
#     "Supervisor",
#     lambda state:
#     "Report_Writer" if len(state["reviewer_final_overview"]) == 4
#     else "Supervisor"
# )

app = app_builder.compile()

# Compile the graph
graphSupervisor = app_builder.compile()

# Save as PNG
graph_image = graphSupervisor.get_graph(xray=1).draw_mermaid_png()
with open("supervisor_graph_diagram.png", "wb") as file:
    file.write(graph_image)
print("Saved as PNG 'supervisor_graph_diagram.png'")

# Thread configuration and graph input
thread = {"configurable": {"thread_id": "1"}}

user_input = {
    "topic": "Help a multinational manufacturing company in their journey to product management maturity.",
}

response = graphSupervisor.invoke(user_input, thread)

print(response)

==================

states.py
CONTENT:
==================
import operator
from typing import List, Annotated

from langgraph.graph import MessagesState
from pydantic import BaseModel, Field
from typing_extensions import TypedDict


class ResearchTeam(BaseModel):
    name: str = Field(
        description="Use only provided in system message names"
    )

    description: str = Field(
        description="Short description of what this team is response for."
    )

    analyst_prompt: str = Field(
        description="The specific prompt for the analyst in the context of the research topic. "
                    "Clearly defines the focus area such as 'Human Resources' or 'Business Process'. "
                    "\n +"
                    "A description of the analyst's focus, key competencies, tasks within the project, "
                    "concerns, and motives. This should align with the research topic and the analyst's role."
    )

    reviewer_prompt: str = Field(
        description="The specific prompt for the reviewer in the context of the research topic. "
                    "Clearly defines the focus area such as 'Human Resources' or 'Business Process'. "
                    "\n +"
                    "A description of the reviewer's focus, key competencies, tasks within the project, "
                    "concerns, and motives. This should align with the research topic and the reviewer's role."
    )

    @property
    def experts(self) -> str:
        """
        Provides a detailed representation of the research team's persona,
        including its name, description, and the specific prompts for the analyst and reviewer.
        """
        return (
            f"Team Name: {self.name}\n"
            f"Description: {self.description}\n\n"
            f"Analyst Prompt:\n{self.analyst_prompt}\n\n"
            f"Reviewer Prompt:\n{self.reviewer_prompt}\n"
        )


class Perspectives(BaseModel):
    teams: List[ResearchTeam] = Field(
        description="List of research teams where each team contains name, description and analyst - reviewer duo prompts",
    )


# Individual state for each analyst and reviewer team
class ResearchState(MessagesState):
    # Topic assigned to the analyst
    description: str  # Description of team's responsibility and capabilities
    # Questionnaire results or user input
    reviews: Annotated[List[str], operator.add]  # Four reviewers answers
    analyst_prompt: str  # Their info
    reviewer_prompt: str


def deduplicate_merge(old_reviews: List[str], new_reviews: List[str]) -> List[str]:
    return list(set(old_reviews).union(new_reviews))

# Overall state for the supervisor
class OverallState(TypedDict):
    topic: str  # Overall topic of analysis
    questionnaire: str  # Questionnaire results or user input
    reviews: Annotated[List[str], deduplicate_merge]  # Four reviewers answers
    final_report: str  # Final report generated after all analysts complete their tasks
    teams: List[ResearchTeam]

==================

supervisor_node.py
CONTENT:
==================
import json
import os
from typing import List
from dotenv import load_dotenv
from langchain.tools import tool
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.constants import Send
from langgraph.constants import END

from graphSupervisor.states import OverallState, Perspectives

# LLM Initialization
load_dotenv()
llm = ChatOpenAI(model=os.getenv("MODEL_SUPERVISOR"), temperature=0)

team_creation_instructions = """
You are tasked with creating AI research teams, each consisting of an analyst and a reviewer. Follow these instructions:
Use provided in prompts names
1. Review the provided research topic.
2. Generate four research teams strictly using provided names:
    a. **HR_Team**: Focused on HR issues like team dynamics, performance, and training.
    b. **BP_Team**: Specializing in process optimization and automation.
    c. **KM_Team**: Concentrating on knowledge sharing and tools.
    d. **IT_Team**: Addressing IT strategies and tools.
3. Each team must have explicitly provided name, description and prompts reflecting their responsibilities.
"""


def define_edge(state: OverallState):
    """
    Initializes states for each research team.
    """
    # print("This is log info FROM DEFINE_EDGE about reviews list length: " + str(len(state["reviews"])))

    if "final_report" in state:
        return END

    if len(state["reviews"]) >= 4:
        return "Report_Writer"

    topic = state["topic"]
    teams = state["teams"]
    print(f"Initializing research teams for topic: \n\t{topic}")

    return [
        Send(
            team["name"],
            {
                "topic": topic,  # Topic assigned to the analyst
                "description": team["description"],
                "questionnaire": "=====",
                "messages": [],
                "reviews": [],
                "analyst_prompt": team["analyst_prompt"],
                "reviewer_prompt": team["reviewer_prompt"],
            }
        ) for team in teams
    ]


@tool
def create_research_teams_tool(topic: str) -> dict:
    """
    Generates a list of research teams based on the given topic.
    """

    print(f"Creating research teams on topic: \n\t{topic}")
    structured_llm = llm.with_structured_output(Perspectives)

    # LLM Query
    system_message = SystemMessage(content=team_creation_instructions)
    human_message = HumanMessage(content=f"Generate the teams for the topic: {topic}.")

    # Teams generation
    perspectives: Perspectives = structured_llm.invoke([system_message, human_message])

    # Serialize
    serialized_teams = [
        {
            "name": team.name,
            "description": team.description,
            "analyst_prompt": team.analyst_prompt,
            "reviewer_prompt": team.reviewer_prompt,
        }
        for team in perspectives.teams
    ]

    return {"teams": serialized_teams}


def supervisor_node(state: OverallState):
    """
    Supervisor node for orchestrating the research workflow.
    """
    # print("This is log info FROM SUPERVISOR about reviews list length: " + str(len(state["reviews"])))

    if "reviews" not in state:
        state["reviews"] = []

    if "teams" not in state or not state["teams"]:
        # Generate teams and initialize states
        generated_teams = create_research_teams_tool.invoke({"topic": state["topic"]})
        state["teams"] = generated_teams["teams"]

    reviews = state["reviews"]

    return state


# Example usage
# if __name__ == "__main__":
#     # Mock OverallState for demonstration
#     state = OverallState(topic="Digital Transformation in Organizations")
#
#     print("initial_state: ", json.dumps(state, indent=4, ensure_ascii=False))
#
#     # Invoke the model with the tools and initial state
#     supervisor_node(state)
#
#     # Print the updated state
#     print("update_state:", json.dumps(state, indent=4, ensure_ascii=False))

==================

team_node.py
CONTENT:
==================
import os
from langgraph.types import *
from typing import Literal
from langchain_openai import ChatOpenAI
from langgraph.constants import END

from graphSupervisor.states import ResearchState



llm = ChatOpenAI(model_name=os.getenv("MODEL"))


def analyst_node(state: ResearchState):
    prompt = state["analyst_prompt"]
    descr = state["analyst_prompt"][0:15]
    return {"messages": ["Hello world Assystent: " + descr]}


def reviewer_node(state: ResearchState):
    prompt = state["reviewer_prompt"]
    descr = state["reviewer_prompt"][0:15]
    print(len(state.get("messages", [])))
    return {"messages": ["Hello world Reviewer: " + descr]}



def should_continue(state: ResearchState):
    # Check if the number of messages is 6 or more
    if len(state.get("messages", [])) >= 6:
        # Return the END constant and the overall state update
        state["reviews"].append(state["messages"][-1])
        return END

    # If the condition is not met, return the next node
    return "Analyst"


==================

report_writer_node.py
CONTENT:
==================
from graphSupervisor.states import OverallState


def report_writer(state: OverallState):
    topic = state["topic"]
    # prompt = f"You are tasked to summarize teams resolutions messages about this {topic}"
    print("report_writer node activated!!")
    print(len(state["reviews"]))
    return {"final_report": ["Good game"]}

==================

